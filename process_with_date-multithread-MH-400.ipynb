{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unified_with_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer, TweetTokenizer, WordPunctTokenizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "VALUES = ['>>>=', '>>=', '<<=',  '%=', '^=', '|=', '&=', '/=',\n",
    "                  '*=', '-=', '+=', '<<', '--', '++', '||', '&&', '!=',\n",
    "                  '>=', '<=', '==', '%', '^', '|', '&', '/', '*', '-',\n",
    "                  '+', ':', '?', '~', '!', '<', '>', '=', '...', '->', '::', '\\\\', '\\\\\\\\', '\\*', '*\\\\', '\\\\\\\\\\\\']\n",
    "INFIX = ['||', '&&', '|', '^', '&', '==', '!=', '<', '>', '<=', '>=', \n",
    "             '<<', '>>', '>>>', '+', '-', '*', '/', '%']\n",
    "PREFIX = ['++', '--', '!', '~', '+', '-']\n",
    "POSTFIX = ['++', '--']\n",
    "ASSIGNMENT = ['=', '+=', '-=', '*=', '/=', '&=', '|=', '^=', '%=', '<<=', '>>=', '>>>=']\n",
    "LAMBDA = ['->']\n",
    "COMMENT = ['//', '/*', '*/']\n",
    "METHOD_REFERENCE = ['::']\n",
    "\n",
    "WHITESPACE_DICT = {\"                \":'<|16-s|>', \n",
    "                   \"            \":'<|12-s|>', \n",
    "                   \"        \":'<|8-s|>', \n",
    "                   \"    \":'<|4-s|>', \n",
    "                   \"  \":'<|2-s|>', \" \":'<|s|>',\n",
    "                   \"\\t\\t\\t\\t\":'<|4-t|>',\"\\t\\t\\t\":'<|3-t|>',\"\\t\\t\":'<|2-t|>',\"\\t\":'<|t|>',\"\\n\":'<|nl|>'}\n",
    "\n",
    "WHITESPACES = [WHITESPACE_DICT[x] for x in WHITESPACE_DICT]\n",
    "\n",
    "REVERSE_WHITESPACE_DICT = {}\n",
    "for key in WHITESPACE_DICT:\n",
    "    value = WHITESPACE_DICT[key]\n",
    "    REVERSE_WHITESPACE_DICT[value] = key\n",
    "\n",
    "CUSTOM_TOKEN = [\"<|startcode|>\", \"<|endcode|>\", \"<|startfocus|>\", \"<|endfocus|>\", \"<|startcomment|>\", \"<|endcomment|>\", \n",
    "                   \"<|stringliteral|>\", \"<|singlelinecomment|>\", \"<|multilinecomment|>\", \"<|del|>\"]\n",
    "\n",
    "values = list(set(INFIX+PREFIX+POSTFIX+ASSIGNMENT+LAMBDA+COMMENT+METHOD_REFERENCE))\n",
    "token_phrases = []\n",
    "word_punct_tokenizer = WordPunctTokenizer()\n",
    "for tok in CUSTOM_TOKEN+WHITESPACES:\n",
    "    temp = tuple(word_punct_tokenizer.tokenize(tok))\n",
    "    token_phrases.append(temp)\n",
    "for w in values:\n",
    "    temp = tuple(MWETokenizer().tokenize(w))\n",
    "    if len(temp) > 1:\n",
    "        token_phrases.append(temp)\n",
    "\n",
    "word_punct_tokenizer = WordPunctTokenizer()\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "mwe_tokenizer = MWETokenizer(token_phrases, separator=\"\")\n",
    "\n",
    "def state(c):\n",
    "    n = ord(c)\n",
    "    if n>=97 and n<=122: # lower case\n",
    "        return 1\n",
    "    elif n>=65 and n<=90: # upper case\n",
    "        return 2\n",
    "    elif n>=48 and n<=57: # numbers\n",
    "        return 3\n",
    "    elif c.isspace(): # whitespaces\n",
    "        return 4\n",
    "    elif c in ['_', '$']: \n",
    "        return 5\n",
    "    elif n < 128:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "def space_up(s):\n",
    "    if s is None or s == \"\":\n",
    "        return \"\"\n",
    "    new_s = s[0]\n",
    "    for i in range(1,len(s)):\n",
    "        prev_state = state(s[i-1])\n",
    "        curr_state = state(s[i])\n",
    "        if prev_state in [1,2] and curr_state in [3]:\n",
    "            new_s += \" \"\n",
    "        elif prev_state in [1] and curr_state in [2]:\n",
    "            new_s += \" \"\n",
    "        elif prev_state in [3] and curr_state in [1,2]:\n",
    "            new_s += \" \"\n",
    "        elif prev_state in [1,2,3] and curr_state in [5]:\n",
    "            new_s += \" \"\n",
    "        elif prev_state in [5] and curr_state in [1,2,3]:\n",
    "            new_s += \" \"\n",
    "        new_s+=s[i]\n",
    "    return new_s\n",
    "\n",
    "def white_space_tokenize(s):\n",
    "    for x in WHITESPACE_DICT:\n",
    "        s = s.replace(x, WHITESPACE_DICT[x])\n",
    "    for key in REVERSE_WHITESPACE_DICT:\n",
    "        #val = REVERSE_WHITESPACE_DICT[x]\n",
    "        s = s.replace(key, \" \"+key+\" \")\n",
    "    return s\n",
    "\n",
    "def extreme_tokenization(comment):\n",
    "    comment = white_space_tokenize(comment)\n",
    "    comment = space_up(comment)\n",
    "    tokenized = tweet_tokenizer.tokenize(comment)\n",
    "    tokenized = word_punct_tokenizer.tokenize(' '.join(tokenized))\n",
    "    tokenized = mwe_tokenizer.tokenize(tokenized)\n",
    "    tokenized_comment = ' '.join(tokenized)\n",
    "    tokenized_comment = re.sub(r'[^\\x00-\\x7f]',r'', tokenized_comment)\n",
    "    tokenized = tokenized_comment.split()\n",
    "    return tokenized\n",
    "\n",
    "def extreme_detokenization(tokens):\n",
    "    s = \"\"\n",
    "    for token in tokens:\n",
    "        if token in REVERSE_WHITESPACE_DICT:\n",
    "            s+= REVERSE_WHITESPACE_DICT[token]\n",
    "        else:\n",
    "            s+= token\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n{'actual_line_number': 71, 'base_code_line_number': 73, 'base_patch_number': 3, 'changed_code': '    /*', 'changed_patch_number': 7, 'code_file_name': 'android_3478', 'comment_id': '3745e284_1e49cdaa', 'line_change': 2, 'message': '{@link android.icu.impl.OlsonTimeZone} ?', 'previous_code': '     /*'}\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import path\n",
    "import json\n",
    "import re\n",
    "import subprocess\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from tqdm import tqdm\n",
    "nltk.download('punkt')\n",
    "\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "def read(path):\n",
    "    return open(path, 'r', encoding = 'utf-8').read()\n",
    "\n",
    "\n",
    "BASE=\"C:/research_stuff/codes/\"\n",
    "unique_data = getJsonData('E:/APR/DATA/unique_data_with_date_and_index.json')\n",
    "data = unique_data[1020]\n",
    "code_file_name = data['file_name']\n",
    "base_patch_number = data['base_patch_number']\n",
    "main_code_path = BASE+code_file_name+'/'+str(base_patch_number)+'.java'\n",
    "main_code = read(main_code_path)\n",
    "\n",
    "\n",
    "def get_source_target(file1, file2, line_number, change_window_size=5):\n",
    "    source_target = subprocess.check_output(['java', '-jar', 'ChangedLine_status.jar', \\\n",
    "                                file1, file2, str(line_number), str(change_window_size)]).decode(\"utf-8\")\n",
    "    (status, source, target) = source_target.split(\"<|sep|>\")\n",
    "    return status, source, target\n",
    "\n",
    "def end_scope(start_index, lines):\n",
    "    #print(lines)\n",
    "    counter = 0\n",
    "    end_index = -1\n",
    "    found = False\n",
    "    for index in range(start_index, len(lines), 1):\n",
    "        #print(lines[index])\n",
    "        #print(counter)\n",
    "        for char in lines[index]:\n",
    "            if(char=='{'):\n",
    "                counter+=1\n",
    "                found = True\n",
    "            elif(char == \"}\"):\n",
    "                counter-=1\n",
    "                found = True\n",
    "            if(counter==0 and found):\n",
    "                end_index = index\n",
    "                break\n",
    "        if end_index!=-1:\n",
    "            break\n",
    "    return end_index\n",
    "\n",
    "unique_data_processed = []\n",
    "MAX_NUM_TOKEN = 400\n",
    "UP_TOKEN = MAX_NUM_TOKEN//2\n",
    "c = 0\n",
    "ec = 0\n",
    "errors = []\n",
    "#for idx, data in enumerate(unique_data):#[2428:2429]#[1000:1001]\n",
    "\n",
    "def process(data):    \n",
    "    code_file_name = data['file_name']\n",
    "    base_patch_number = data['base_patch_number']\n",
    "    changed_patch_number = data['changed_patch_number']\n",
    "    main_code_path = BASE+code_file_name+'/'+str(base_patch_number)+'.java'\n",
    "    changed_code_path = BASE+code_file_name+'/'+str(changed_patch_number)+'.java'\n",
    "    line_no = data['line_number']\n",
    "    main_code = read(main_code_path)\n",
    "    changed_code = read(changed_code_path)\n",
    "    sample = main_code\n",
    "    message = data['message']\n",
    "    comment_id = data['comment_id']\n",
    "    source = \"\"\n",
    "    target=''\n",
    "    try:\n",
    "        status, source, target = get_source_target(main_code_path, changed_code_path,line_no)\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "    sample = source\n",
    "    data_dic = {}\n",
    "    data_dic['status'] = status\n",
    "    data_dic['message'] = message\n",
    "    \n",
    "    data_dic['comment_id'] = comment_id\n",
    "    data_dic['target'] = target[:-2]\n",
    "    #data_dic['source'] = source\n",
    "    #data_dic['idx'] = c\n",
    "    func_list = []\n",
    "    data_dic['code_snippet'] = main_code\n",
    "    data_dic['prime_var_dic'] = {}\n",
    "    #print(sample)\n",
    "    classes = re.findall(r\"(?:(public\\s))?(class)\\s([^\\n\\s]*)\", sample)\n",
    "    lines = sample.split('\\n')\n",
    "    class_list = []\n",
    "    sp_start_func= -1\n",
    "    sp_end_func= len(sample.split('\\n'))   \n",
    "    for cls_tpl in classes:\n",
    "        s = \"\".join(cls_tpl[-1])\n",
    "        s = s.strip()\n",
    "        class_list.append(s) ## class list\n",
    "        cls = s\n",
    "        #print(s)\n",
    "        start_index = -1\n",
    "        for i in range(len(lines)):\n",
    "            if cls in lines[i]:\n",
    "                start_index = i\n",
    "                break\n",
    "        #print(start_index)\n",
    "        end_index = end_scope(start_index, lines)\n",
    "        #print(end_index)\n",
    "        class_scope_dic = {}\n",
    "        for i in range(start_index, end_index+1):\n",
    "            class_scope_dic[i] = True\n",
    "        funcs = re.findall(r\"(public|protected|private|static|\\s) +([\\w\\<\\>\\[\\]]+\\s+(\\w+)) *\\([^\\)]*\\) *(\\{?|[^;])\", \"\\n\".join(lines[start_index:end_index+1]))\n",
    "        func_scopes = []\n",
    "        #print(funcs)\n",
    "        #continue\n",
    "        visited_func = set()\n",
    "        for func in funcs:\n",
    "            #print(func)\n",
    "            if(func[-1]!= \"{\"):\n",
    "                continue\n",
    "            fc = list(func)\n",
    "            fc = fc[-3]\n",
    "            s = \"\".join(fc)\n",
    "            s = s.strip()\n",
    "            #func_list.append(s) ## function list\n",
    "            #print(func_list)\n",
    "            \n",
    "            for index in range(start_index, end_index+1, 1):\n",
    "                if s in lines[index]:\n",
    "                    start_func = index\n",
    "                    end_func = end_scope(index, lines)\n",
    "                    \n",
    "                    func_scopes.append((start_func,end_func))\n",
    "                    if s not in visited_func:\n",
    "                        visited_func.add(s)\n",
    "                        func_list.append(lines[index].replace(\"{\", \"\").strip())\n",
    "\n",
    "                    if(start_func<=line_no<=end_func):\n",
    "                        special_func = \"\\n\".join(lines[start_func:end_func+1])\n",
    "                        #data_dic['code_snippet'] = special_func\n",
    "                        #nonlocal sp_start_func\n",
    "                        sp_start_func= start_func\n",
    "                        #nonlocal sp_end_func\n",
    "                        sp_end_func= end_func\n",
    "\n",
    "        for func_sc in func_scopes:\n",
    "            for i in range(func_sc[0], func_sc[1]+1):\n",
    "                class_scope_dic[i] = False\n",
    "        prime_var_list = []\n",
    "        dic_vars = {}\n",
    "        for i in range(start_index, end_index+1):\n",
    "            if class_scope_dic[i]==True:\n",
    "                #prime_vars = re.findall(r\"\"\"\"[^\"]*\"|((?=_[a-z_0-9]|[a-z])[a-z_0-9]+((?=\\s*=)))\"\"\",lines[i])\n",
    "                if '(' not in lines[i] and \"return\" not in lines[i] and \"extends\" not in lines[i]:\n",
    "                    prime_vars = re.findall(r\"\"\"(\\w+\\s+)([a-zA-Z_][a-zA-Z0-9_]*)\"\"\", lines[i])\n",
    "                    if len(prime_vars)==2:\n",
    "                        if(len(prime_vars[1])==2 and prime_vars[1][1] in dic_vars.keys()):\n",
    "                            dic_vars[prime_vars[1][1]]+=1\n",
    "                        elif len(prime_vars[1])==2:\n",
    "                            dic_vars[prime_vars[1][1]] =1\n",
    "        #if(len(list(dic_vars.keys()))>0):\n",
    "            #print(dic_vars)\n",
    "        data_dic['prime_var_dic'] = dic_vars\n",
    "    data_dic['class_list'] = class_list\n",
    "    data_dic['func_list'] = func_list\n",
    "    \n",
    "    #print(\"specials   ###\", sp_start_func, sp_end_func)\n",
    "    \n",
    "    #if not (0 < len(extreme_tokenization(data_dic['code_snippet']))<MAX_NUM_TOKEN): \n",
    "    #print(\"comes\")\n",
    "    up_count = 0\n",
    "    up_done = False\n",
    "    down_count = 0\n",
    "    down_done = False\n",
    "    splitted = sample.split(\"\\n\")\n",
    "    while(1):\n",
    "        #print(max(0, line_no-up_count),line_no+1)\n",
    "        if len(extreme_tokenization(\"\\n\".join(splitted[max(0,sp_start_func, line_no-up_count):line_no+1])))<UP_TOKEN:\n",
    "            if(up_count==line_no):\n",
    "                break\n",
    "            up_count+=1\n",
    "        else:\n",
    "            up_count-=1\n",
    "            break\n",
    "            #print(\"something is wrong\")\n",
    "    #print(len(extreme_tokenization(\"\\n\".join(splitted[max(0,sp_start_func, line_no-up_count):line_no+1]))))\n",
    "    #print(up_count)\n",
    "    while(1):\n",
    "        if len(extreme_tokenization(\"\\n\".join(splitted[max(0,sp_start_func, line_no-up_count):min(line_no+down_count+1,sp_end_func, len(splitted))])))<MAX_NUM_TOKEN:\n",
    "            #print(len(extreme_tokenization(\"\\n\".join(splitted[(line_no-up_count):min(line_no+down_count+1,sp_end_func, len(splitted))]))))\n",
    "            #print(MAX_NUM_TOKEN)\n",
    "            if(down_count==len(splitted)):\n",
    "                break\n",
    "            down_count+=1\n",
    "        else:\n",
    "            down_count-=1\n",
    "            break\n",
    "    #print(line_no+down_count+1,sp_end_func, len(splitted), up_count)\n",
    "    code_snippet = \"\\n\".join(splitted[max(0,sp_start_func, line_no-up_count):min(line_no+down_count+1,sp_end_func, len(splitted))])\n",
    "    #print(\"length = \", len(extreme_tokenization(code_snippet)))\n",
    "    '''\n",
    "    #print(len(extreme_tokenization(\"\\n\".join(splitted[(line_no-up_count):min(line_no+down_count+1,sp_end_func, len(splitted))]))))\n",
    "    #print(up_count, down_count)\n",
    "    #print(max(0,sp_start_func, line_no-up_count),min(line_no+down_count+1,sp_end_func, len(splitted)))\n",
    "    \n",
    "    #print(line_no)\n",
    "    #print(len(extreme_tokenization(\"\\n\".join(splitted[41-14:41+50]))))\n",
    "    if sp_start_func != -1:\n",
    "        #print(\"comes\")\n",
    "        #data_dic['code_snippet'] = \"\\n\".join(splitted[sp_start_func:sp_end_func+1])\n",
    "        \n",
    "        if(\"startfocus\" in splitted[sp_start_func-1]):\n",
    "            sp_start_func-=1\n",
    "        if sp_end_func <=len(splitted)-2 and \"endfocus\" in splitted[sp_end_func+1]:\n",
    "            sp_end_func+=2\n",
    "        if sp_end_func <=len(splitted)-1 and \"endfocus\" in splitted[sp_end_func]:\n",
    "            sp_end_func+=1\n",
    "        #print(\" \".join(splitted[sp_start_func:sp_end_func+1]))\n",
    "        #print(sp_start_func)\n",
    "        #print(sp_end_func)\n",
    "        code_snippet = \"\\n\".join(splitted[sp_start_func:sp_end_func+1])\n",
    "        #print(\"in function\")\n",
    "        \n",
    "    else:\n",
    "        #data_dic['code_snippet'] = \"\\n\".join(splitted[(line_no-up_count):(line_no+down_count+1)])\n",
    "        #print(\"not in function\")\n",
    "        if(\"startfocus\" in splitted[(line_no-up_count-1)]):\n",
    "            up_count+=1\n",
    "        if line_no+down_count <=len(splitted)-1 and \"endfocus\" in splitted[line_no+down_count]:\n",
    "            down_count+=1\n",
    "        code_snippet = \"\\n\".join(splitted[(line_no-up_count):(line_no+down_count+1)])\n",
    "        #print(line_no-up_count)\n",
    "        #print(line_no+down_count+1)\n",
    "        #print(code_snippet)\n",
    "    #print(code_snippet)\n",
    "    #print(data_dic['func_list'])\n",
    "    '''\n",
    "    if \"<|startfocus|>\" in code_snippet and \"<|endfocus|>\" not in code_snippet:\n",
    "        code_snippet =code_snippet+  \"\\n<|endfocus|>\"\n",
    "    if \"<|startfocus|>\" not in code_snippet and \"<|endfocus|>\" in code_snippet:\n",
    "        code_snippet = \"<|startfocus|>\\n\"+code_snippet\n",
    "        \n",
    "    data_dic['tokenized_code_snippet'] = extreme_tokenization(code_snippet)#data_dic['code_snippet'])\n",
    "    data_dic['tokenized_target'] = extreme_tokenization(data_dic['target'])\n",
    "    data_dic['tokenized_comment'] = extreme_tokenization(data_dic['message'])\n",
    "    data_dic['code_snippet'] = code_snippet\n",
    "    #print(\"specials   ###\", sp_start_func, sp_end_func)\n",
    "\n",
    "    \n",
    "    #print(code_snippet)\n",
    "    #print(\"#################\")\n",
    "    #print(data_dic)\n",
    "    #print(source)\n",
    "    #data_dic['actual_line_number'] = data['line_number']\n",
    "    #data_dic['code_snippet'] = data['code_snippet']\n",
    "    \n",
    "    data_dic['global_index'] = data['global_index']\n",
    "    data_dic['base_code_line_number'] = data['line_number']\n",
    "    data_dic['base_patch_number'] = data['base_patch_number']\n",
    "    data_dic['changed_patch_number'] = data['changed_patch_number']\n",
    "    data_dic['code_file_name'] = data['file_name']\n",
    "    data_dic['comment_id'] = data['comment_id']\n",
    "    data_dic['message'] = data['message']\n",
    "    data_dic['line_change'] = data['line_change']\n",
    "    data_dic['written_on'] = data['written_on']\n",
    "    data_dic['project_name'] = data['project_name']\n",
    "    #print(\"length\", len(data_dic['tokenized_code_snippet']))\n",
    "    #print(\"token length\",len(data_dic['tokenized_code_snippet']))\n",
    "    #return data_dic\n",
    "    \n",
    "    \n",
    "    if \"<|startfocus|>\" in code_snippet and \"<|endfocus|>\" in code_snippet:\n",
    "        unique_data_processed.append(data_dic)\n",
    "        if len(data_dic['tokenized_code_snippet'])>401:\n",
    "            print(\"length greater than 401 found global idx\", data['global_index'])\n",
    "        if(len(unique_data_processed)%100==0):\n",
    "            print(\"data size = \", len(unique_data_processed))\n",
    "    '''\n",
    "    print(idx)\n",
    "    if(idx%1000==0):\n",
    "        print(idx)\n",
    "        print(c)\n",
    "        pprint(data_dic)\n",
    "    '''\n",
    "'''\n",
    "{'actual_line_number': 71, 'base_code_line_number': 73, 'base_patch_number': 3, 'changed_code': '    /*', 'changed_patch_number': 7, 'code_file_name': 'android_3478', 'comment_id': '3745e284_1e49cdaa', 'line_change': 2, 'message': '{@link android.icu.impl.OlsonTimeZone} ?', 'previous_code': '     /*'}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = process(unique_data[25019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx , dt in enumerate(unique_data):\n",
    "    if(len(dt['tokenized_code_snippet']))>=400:\n",
    "        #print(unique_data['global_index'])\n",
    "        print(len(process(unique[unique_data[idx]['global_index']])['code_snippet']))\n",
    "#process(unique_data[545])['code_snippet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,json\n",
    "import csv\n",
    "import _thread\n",
    "import threading\n",
    "import time\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "def read(path):\n",
    "    return open(path, 'r', encoding = 'utf-8').read()\n",
    "\n",
    "\n",
    "#BASE=\"E:/codes/\"\n",
    "\n",
    "file_size = len(unique_data)\n",
    "batch_size = 1000\n",
    "\n",
    "def translate(file_no):\n",
    "    for x in range(file_no*batch_size, min(file_size,(file_no+1)*batch_size)):\n",
    "        process(unique_data[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithread Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file =  0\n",
      "processing file =  1\n",
      "processing file =  2\n",
      "processing file =  3\n",
      "processing file =  4\n",
      "processing file =  5\n",
      "processing file =  6\n",
      "processing file =  7\n",
      "processing file =  8\n",
      "processing file =  9\n",
      "processing file =  10\n",
      "processing file =  11\n",
      "processing file =  12\n",
      "processing file =  13\n",
      "processing file =  14\n",
      "processing file =  15\n",
      "processing file =  16\n",
      "processing file =  17\n",
      "processing file =  18\n",
      "processing file =  19\n",
      "processing file =  20\n",
      "processing file =  21\n",
      "processing file =  22\n",
      "processing file =  23\n",
      "processing file =  24\n",
      "processing file =  25\n",
      "processing file =  26\n",
      "processing file =  27\n",
      "processing file =  28\n",
      "processing file =  29\n",
      "processing file =  30\n",
      "data size =  processing file = 100 31\n",
      "\n",
      "processing file =  32\n",
      "processing file =  33\n",
      "processing file =  34\n",
      "processing file =  35\n",
      "processing file =  data size =  36\n",
      "200\n",
      "processing file =  37\n",
      "processing file =  38\n",
      "processing file =  39\n",
      "processing file =  40\n",
      "processing file =  41\n",
      "processing file =  42\n",
      "processing file =  43data size = \n",
      " 300processing file =  \n",
      "44\n",
      "processing file =  45\n",
      "processing file =  46\n",
      "processing file =  47\n",
      "processing file =  48\n",
      "processing file =  49data size = \n",
      " 400processing file =  \n",
      "50\n",
      "processing file =  51\n",
      "processing file =  52\n",
      "data size = processing file =   53500\n",
      "\n",
      "processing file =  54\n",
      "processing file =  55\n",
      "processing file =  56\n",
      "processing file =  57\n",
      "data size = processing file =   60058\n",
      "\n",
      "processing file =  59\n",
      "processing file =  60\n",
      "processing file =  61\n",
      "data size =  processing file = 700 \n",
      "62\n",
      "processing file =  63\n",
      "processing file =  64\n",
      "processing file =  65\n",
      "data size =  processing file = 800 \n",
      "66\n",
      "processing file =  67\n",
      "processing file =  68\n",
      "processing file =  data size =  69\n",
      "900\n",
      "processing file =  70\n",
      "processing file =  71\n",
      "processing file =  72\n",
      "processing file =  73\n",
      "data size = processing file =  1000 \n",
      "74\n",
      "processing file =  75\n",
      "processing file = data size =   761100\n",
      "\n",
      "processing file =  77\n",
      "processing file =  78\n",
      "processing file =  data size = 79 \n",
      "1200processing file = \n",
      " 80\n",
      "processing file =  81\n",
      "processing file =  82\n",
      "processing file =  data size =  83\n",
      "1300\n",
      "processing file =  84\n",
      "data size = processing file =  1400 \n",
      "85\n",
      "processing file =  86\n",
      "processing file =  87\n",
      "processing file =  data size =  88\n",
      "1500processing file = \n",
      " 89\n",
      "processing file = data size =   160090\n",
      "\n",
      "processing file =  91\n",
      "processing file =  92\n",
      "processing file =  93\n",
      "processing file =  94data size =  \n",
      "1700processing file =  \n",
      "95\n",
      "processing file =  96\n",
      "processing file =  data size =  97\n",
      "1800\n",
      "processing file =  98\n",
      "processing file =  99\n",
      "processing file =  100data size =  \n",
      "1900\n",
      "data size =  2000\n",
      "data size =  2100\n",
      "data size =  2200\n",
      "data size =  2300\n",
      "data size =  2400\n",
      "data size =  2500\n",
      "data size =  2600\n",
      "data size =  2700\n",
      "data size =  2800\n",
      "data size =  2900\n",
      "data size =  3000\n",
      "data size =  3100\n",
      "data size =  3200\n",
      "data size =  3300\n",
      "data size =  3400\n",
      "data size =  3500\n",
      "data size =  3600\n",
      "data size =  3700\n",
      "data size =  3800\n",
      "data size =  3900\n",
      "data size =  4000\n",
      "data size =  4100\n",
      "data size =  4200\n",
      "data size =  4300\n",
      "data size =  4400\n",
      "data size =  4500\n",
      "data size =  4600\n",
      "data size =  4700\n",
      "data size =  4800\n",
      "data size =  4900\n",
      "data size =  5000\n",
      "data size =  5100\n",
      "data size =  5200\n",
      "data size =  5300\n",
      "data size =  5400\n",
      "data size =  5500\n",
      "data size =  5600\n",
      "data size =  5700\n",
      "data size =  5800\n",
      "data size =  5900\n",
      "data size =  6000\n",
      "data size =  6100\n",
      "data size =  6200\n",
      "data size =  6300\n",
      "data size =  6400\n",
      "data size =  6500\n",
      "data size =  6600\n",
      "data size =  6700\n",
      "data size =  6800\n",
      "data size =  6900\n",
      "data size =  7000\n",
      "data size =  7100\n",
      "data size =  7200\n",
      "data size =  7300\n",
      "data size =  7400\n",
      "data size =  7500\n",
      "data size =  7600\n",
      "data size =  7700\n",
      "data size =  7800\n",
      "data size =  7900\n",
      "data size =  8000\n",
      "data size =  8100\n",
      "data size =  8200\n",
      "data size =  8300\n",
      "data size =  8400\n",
      "data size =  8500\n",
      "data size =  8600\n",
      "data size =  8700\n",
      "data size =  8800\n",
      "data size =  8900\n",
      "data size =  9000\n",
      "data size =  9100\n",
      "data size =  9200\n",
      "data size =  9300\n",
      "data size =  9400\n",
      "data size =  9500\n",
      "data size =  9600\n",
      "data size =  9700\n",
      "data size =  9800\n",
      "data size =  9900\n",
      "data size =  10000\n",
      "data size =  10100\n",
      "data size =  10200\n",
      "data size =  10300\n",
      "data size =  10400\n",
      "data size =  10500\n",
      "data size =  10600\n",
      "data size =  10700\n",
      "data size =  10800\n",
      "data size =  10900\n",
      "data size =  11000\n",
      "data size =  11100\n",
      "data size =  11200\n",
      "data size =  11300\n",
      "data size =  11400\n",
      "data size =  11500\n",
      "data size =  11600\n",
      "data size =  11700\n",
      "data size =  11800\n",
      "data size =  11900\n",
      "data size =  12000\n",
      "data size =  12100\n",
      "data size =  12200\n",
      "data size =  12300\n",
      "data size =  12400\n",
      "data size =  12500\n",
      "data size =  12600\n",
      "data size =  12700\n",
      "data size =  12800\n",
      "data size =  12900\n",
      "data size =  13000\n",
      "data size =  13100\n",
      "data size =  13200\n",
      "data size =  13300\n",
      "data size =  13400\n",
      "data size =  13500\n",
      "data size =  13600\n",
      "data size =  13700\n",
      "data size =  13800\n",
      "data size =  13900\n",
      "data size =  14000\n",
      "data size =  14100\n",
      "data size =  14200\n",
      "data size =  14300\n",
      "data size =  14400\n",
      "data size =  14500\n",
      "data size =  14600\n",
      "data size =  14700\n",
      "data size =  14800\n",
      "data size =  14900\n",
      "data size =  15000\n",
      "data size =  15100\n",
      "data size =  15200\n",
      "data size =  15300\n",
      "data size =  15400\n",
      "data size =  15500\n",
      "data size =  15600\n",
      "data size =  15700\n",
      "data size =  15800\n",
      "data size =  15900\n",
      "data size =  16000\n",
      "data size =  16100\n",
      "data size =  16200\n",
      "data size =  16300\n",
      "data size =  16400\n",
      "data size =  16500\n",
      "data size =  16600\n",
      "data size =  16700\n",
      "data size =  16800\n",
      "data size =  16900\n",
      "data size =  17000\n",
      "data size =  17100\n",
      "data size =  17200\n",
      "data size =  17300\n",
      "data size =  17400\n",
      "data size =  17500\n",
      "data size =  17600\n",
      "data size =  17700\n",
      "data size =  17800\n",
      "data size =  17900\n",
      "data size =  18000\n",
      "data size =  18100\n",
      "data size =  18200\n",
      "data size =  18300\n",
      "data size =  18400\n",
      "data size =  18500\n",
      "data size =  18600\n",
      "data size =  18700\n",
      "data size =  18800\n",
      "data size =  18900\n",
      "data size =  19000\n",
      "data size =  19100\n",
      "data size =  19200\n",
      "data size =  19300\n",
      "data size =  19400\n",
      "data size =  19500\n",
      "data size =  19600\n",
      "data size =  19700\n",
      "data size =  19800\n",
      "data size =  19900\n",
      "data size =  20000\n",
      "data size =  20100\n",
      "data size =  20200\n",
      "data size =  20300\n",
      "data size =  20400\n",
      "data size =  20500\n",
      "data size =  20600\n",
      "data size =  20700\n",
      "data size =  20800\n",
      "data size =  20900\n",
      "data size =  21000\n",
      "data size =  21100\n",
      "data size =  21200\n",
      "data size =  21300\n",
      "data size =  21400\n",
      "data size =  21500\n",
      "data size =  21600\n",
      "data size =  21700\n",
      "data size =  21800\n",
      "data size =  21900\n",
      "data size =  22000\n",
      "data size =  22100\n",
      "data size =  22200\n",
      "data size =  22300\n",
      "data size =  22400\n",
      "data size =  22500\n",
      "data size =  22600\n",
      "data size =  22700\n",
      "data size =  22800\n",
      "data size =  22900\n",
      "data size =  23000\n",
      "data size =  23100\n",
      "data size =  23200\n",
      "data size =  23300\n",
      "data size =  23400\n",
      "data size =  23500\n",
      "data size =  23600\n",
      "data size =  23700\n",
      "data size =  23800\n",
      "data size =  23900\n",
      "data size =  24000\n",
      "data size =  24100\n",
      "data size =  24200\n",
      "data size =  24300\n",
      "data size =  24400\n",
      "data size =  24500\n",
      "data size =  24600\n",
      "data size =  24700\n",
      "data size =  24800\n",
      "data size =  24900\n",
      "data size =  25000\n",
      "data size =  25100\n",
      "data size =  25200\n",
      "data size =  25300\n",
      "data size =  25400\n",
      "data size =  25500\n",
      "data size =  25600\n",
      "data size =  25700\n",
      "data size =  25800\n",
      "data size =  25900\n",
      "data size =  26000\n",
      "data size =  26100\n",
      "data size =  26200\n",
      "data size =  26300\n",
      "data size =  26400\n",
      "data size =  26500\n",
      "data size =  26600\n",
      "data size =  26700\n",
      "data size =  26800\n",
      "data size =  26900\n",
      "data size =  27000\n",
      "data size =  27100\n",
      "data size =  27200\n",
      "data size =  27300\n",
      "data size =  27400\n",
      "data size =  27500\n",
      "data size =  27600\n",
      "data size =  27700\n",
      "data size =  27800\n",
      "data size =  27900\n",
      "data size =  28000\n",
      "data size =  28100\n",
      "data size =  28200\n",
      "data size =  28300\n",
      "data size =  28400\n",
      "data size =  28500\n",
      "data size =  28600\n",
      "data size =  28700\n",
      "data size =  28800\n",
      "data size =  28900\n",
      "data size =  29000\n",
      "data size =  29100\n",
      "data size =  29200\n",
      "data size =  29300\n",
      "data size =  29400\n",
      "data size =  29500\n",
      "data size =  29600\n",
      "data size =  29700\n",
      "data size =  29800\n",
      "data size =  29900\n",
      "data size =  30000\n",
      "data size =  30100\n",
      "data size =  30200\n",
      "data size =  30300\n",
      "data size =  30400\n",
      "data size =  30500\n",
      "data size =  30600\n",
      "data size =  30700\n",
      "data size =  30800\n",
      "data size =  30900\n",
      "data size =  31000\n",
      "data size =  31100\n",
      "data size =  31200\n",
      "data size =  31300\n",
      "data size =  31400\n",
      "data size =  31500\n",
      "data size =  31600\n",
      "data size =  31700\n",
      "data size =  31800\n",
      "data size =  31900\n",
      "data size =  32000\n",
      "data size =  32100\n",
      "data size =  32200\n",
      "data size =  32300\n",
      "data size =  32400\n",
      "data size =  32500\n",
      "data size =  32600\n",
      "data size =  32700\n",
      "data size =  32800\n",
      "data size =  32900\n",
      "data size =  33000\n",
      "data size =  33100\n",
      "data size =  33200\n",
      "data size =  33300\n",
      "data size =  33400\n",
      "data size =  33500\n",
      "data size =  33600\n",
      "data size =  33700\n",
      "data size =  33800\n",
      "data size =  33900\n",
      "data size =  34000\n",
      "data size =  34100\n",
      "data size =  34200\n",
      "data size =  34300\n",
      "data size =  34400\n",
      "data size =  34500\n",
      "data size =  34600\n",
      "data size =  34700\n",
      "data size =  34800\n",
      "data size =  34900\n",
      "data size =  35000\n",
      "data size =  35100\n",
      "data size =  35200\n",
      "data size =  35300\n",
      "data size =  35400\n",
      "data size =  35500\n",
      "data size =  35600\n",
      "data size =  35700\n",
      "data size =  35800\n",
      "data size =  35900\n",
      "data size =  36000\n",
      "data size =  36100\n",
      "data size =  36200\n",
      "data size =  36300\n",
      "data size =  36400\n",
      "data size =  36500\n",
      "data size =  36600\n",
      "data size =  36700\n",
      "data size =  36800\n",
      "data size =  36900\n",
      "data size =  37000\n",
      "data size =  37100\n",
      "data size =  37200\n",
      "data size =  37300\n",
      "data size =  37400\n",
      "data size =  37500\n",
      "data size =  37600\n",
      "data size =  37700\n",
      "data size =  37800\n",
      "data size =  37900\n",
      "data size =  38000\n",
      "data size =  38100\n",
      "data size =  38200\n",
      "data size =  38300\n",
      "data size =  38400\n",
      "data size =  38500\n",
      "data size =  38600\n",
      "data size =  38700\n",
      "data size =  38800\n",
      "data size =  38900\n",
      "data size =  39000\n",
      "data size =  39100\n",
      "data size =  39200\n",
      "data size =  39300\n",
      "data size =  39400\n",
      "data size =  39500\n",
      "data size =  39600\n",
      "data size =  39700\n",
      "data size =  39800\n",
      "data size =  39900\n",
      "data size =  40000\n",
      "data size =  40100\n",
      "data size =  40200\n",
      "data size =  40300\n",
      "data size =  40400\n",
      "data size =  40500\n",
      "data size =  40600\n",
      "data size =  40700\n",
      "data size =  40800\n",
      "data size =  40900\n",
      "data size =  41000\n",
      "data size =  41100\n",
      "data size =  41200\n",
      "data size =  41300\n",
      "data size =  41400\n",
      "data size =  41500\n",
      "data size =  41600\n",
      "data size =  41700\n",
      "data size =  41800\n",
      "data size =  41900\n",
      "data size =  42000\n",
      "data size =  42100\n",
      "data size =  42200\n",
      "data size =  42300\n",
      "data size =  42400\n",
      "data size =  42500\n",
      "data size =  42600\n",
      "data size =  42700\n",
      "data size =  42800\n",
      "data size =  42900\n",
      "data size =  43000\n",
      "data size =  43100\n",
      "data size =  43200\n",
      "data size =  43300\n",
      "data size =  43400\n",
      "data size =  43500\n",
      "data size =  43600\n",
      "data size =  43700\n",
      "data size =  43800\n",
      "data size =  43900\n",
      "data size =  44000\n",
      "data size =  44100\n",
      "data size =  44200\n",
      "data size =  44300\n",
      "data size =  44400\n",
      "data size =  44500\n",
      "data size =  44600\n",
      "data size =  44700\n",
      "data size =  44800\n",
      "data size =  44900\n",
      "data size =  45000\n",
      "data size =  45100\n",
      "data size =  45200\n",
      "data size =  45300\n",
      "data size =  45400\n",
      "data size =  45500\n",
      "data size =  45600\n",
      "data size =  45700\n",
      "data size =  45800\n",
      "data size =  45900\n",
      "data size =  46000\n",
      "data size =  46100\n",
      "data size =  46200\n",
      "data size =  46300\n",
      "data size =  46400\n",
      "data size =  46500\n",
      "data size =  46600\n",
      "data size =  46700\n",
      "data size =  46800\n",
      "data size =  46900\n",
      "data size =  47000\n",
      "data size =  47100\n",
      "data size =  47200\n",
      "data size =  47300\n",
      "data size =  47400\n",
      "data size =  47500\n",
      "data size =  47600\n",
      "data size =  47700\n",
      "data size =  47800\n",
      "data size =  47900\n",
      "data size =  48000\n",
      "data size =  48100\n",
      "data size =  48200\n",
      "data size =  48300\n",
      "data size =  48400\n",
      "data size =  48500\n",
      "data size =  48600\n",
      "data size =  48700\n",
      "data size =  48800\n",
      "data size =  48900\n",
      "data size =  49000\n",
      "data size =  49100\n",
      "data size =  49200\n",
      "data size =  49300\n",
      "data size =  49400\n",
      "data size =  49500\n",
      "data size =  49600\n",
      "data size =  49700\n",
      "data size =  49800\n",
      "data size =  49900\n",
      "data size =  50000\n",
      "data size =  50100\n",
      "data size =  50200\n",
      "data size =  50300\n",
      "data size =  50400\n",
      "data size =  50500\n",
      "data size =  50600\n",
      "data size =  50700\n",
      "data size =  50800\n",
      "data size =  50900\n",
      "data size =  51000\n",
      "data size =  51100\n",
      "data size =  51200\n",
      "data size =  51300\n",
      "data size =  51400\n",
      "data size =  51500\n",
      "data size =  51600\n",
      "data size =  51700\n",
      "data size =  51800\n",
      "data size =  51900\n",
      "data size =  52000\n",
      "data size =  52100\n",
      "data size =  52200\n",
      "data size =  52300\n",
      "data size =  52400\n",
      "data size =  52500\n",
      "data size =  52600\n",
      "data size =  52700\n",
      "data size =  52800\n",
      "data size =  52900\n",
      "data size =  53000\n",
      "data size =  53100\n",
      "data size =  53200\n",
      "data size =  53300\n",
      "data size =  53400\n",
      "data size =  53500\n",
      "data size =  53600\n",
      "data size =  53700\n",
      "data size =  53800\n",
      "data size =  53900\n",
      "data size =  54000\n",
      "data size =  54100\n",
      "data size =  54200\n",
      "data size =  54300\n",
      "data size =  54400\n",
      "data size =  54500\n",
      "data size =  54600\n",
      "data size =  54700\n",
      "data size =  54800\n",
      "data size =  54900\n",
      "data size =  55000\n",
      "data size =  55100\n",
      "data size =  55200\n",
      "data size =  55300\n",
      "data size =  55400\n",
      "data size =  55500\n",
      "data size =  55600\n",
      "data size =  55700\n",
      "data size =  55800\n",
      "data size =  55900\n",
      "data size =  56000\n",
      "data size =  56100\n",
      "data size =  56200\n",
      "data size =  56300\n",
      "data size =  56400\n",
      "data size =  56500\n",
      "data size =  56600\n",
      "data size =  56700\n",
      "data size =  56800\n",
      "data size =  56900\n",
      "data size =  57000\n",
      "data size =  57100\n",
      "data size =  57200\n",
      "data size =  57300\n",
      "data size =  57400\n",
      "data size =  57500\n",
      "data size =  57600\n",
      "data size =  57700\n",
      "data size =  57800\n",
      "data size =  57900\n",
      "data size =  58000\n",
      "data size =  58100\n",
      "data size =  58200\n",
      "data size =  58300\n",
      "data size =  58400\n",
      "data size =  58500\n",
      "data size =  58600\n",
      "data size =  58700\n",
      "data size =  58800\n",
      "data size =  58900\n",
      "data size =  59000\n",
      "data size =  59100\n",
      "data size =  59200\n",
      "data size =  59300\n",
      "data size =  59400\n",
      "data size =  59500\n",
      "data size =  59600\n",
      "data size =  59700\n",
      "data size =  59800\n",
      "data size =  59900\n",
      "data size =  60000\n",
      "data size =  60100\n",
      "data size =  60200\n",
      "data size =  60300\n",
      "data size =  60400\n",
      "data size =  60500\n",
      "data size =  60600\n",
      "data size =  60700\n",
      "data size =  60800\n",
      "data size =  60900\n",
      "data size =  61000\n",
      "data size =  61100\n",
      "data size =  61200\n",
      "data size =  61300\n",
      "data size =  61400\n",
      "data size =  61500\n",
      "data size =  61600\n",
      "data size =  61700\n",
      "data size =  61800\n",
      "data size =  61900\n",
      "data size =  62000\n",
      "data size =  62100\n",
      "data size =  62200\n",
      "data size =  62300\n",
      "data size =  62400\n",
      "data size =  62500\n",
      "data size =  62600\n",
      "data size =  62700\n",
      "data size =  62800\n",
      "data size =  62900\n",
      "data size =  63000\n",
      "data size =  63100\n",
      "data size =  63200\n",
      "data size =  63300\n",
      "data size =  63400\n",
      "data size =  63500\n",
      "data size =  63600\n",
      "data size =  63700\n",
      "data size =  63800\n",
      "data size =  63900\n",
      "data size =  64000\n",
      "data size =  64100\n",
      "data size =  64200\n",
      "data size =  64300\n",
      "data size =  64400\n",
      "data size =  64500\n",
      "data size =  64600\n",
      "data size =  64700\n",
      "data size =  64800\n",
      "data size =  64900\n",
      "data size =  65000\n",
      "data size =  65100\n",
      "data size =  65200\n",
      "data size =  65300\n",
      "data size =  65400\n",
      "data size =  65500\n",
      "data size =  65600\n",
      "data size =  65700\n",
      "data size =  65800\n",
      "data size =  65900\n",
      "data size =  66000\n",
      "data size =  66100\n",
      "data size =  66200\n",
      "data size =  66300\n",
      "data size =  66400\n",
      "data size =  66500\n",
      "data size =  66600\n",
      "data size =  66700\n",
      "data size =  66800\n",
      "data size =  66900\n",
      "data size =  67000\n",
      "data size =  67100\n",
      "data size =  67200\n",
      "data size =  67300\n",
      "data size =  67400\n",
      "data size =  67500\n",
      "data size =  67600\n",
      "data size =  67700\n",
      "data size =  67800\n",
      "data size =  67900\n",
      "data size =  68000\n",
      "data size =  68100\n",
      "data size =  68200\n",
      "data size =  68300\n",
      "data size =  68400\n",
      "data size =  68500\n",
      "data size =  68600\n",
      "data size =  68700\n",
      "data size =  68800\n",
      "data size =  68900\n",
      "data size =  69000\n",
      "data size =  69100\n",
      "data size =  69200\n",
      "data size =  69300\n",
      "data size =  69400\n",
      "data size =  69500\n",
      "data size =  69600\n",
      "data size =  69700\n",
      "data size =  69800\n",
      "data size =  69900\n",
      "data size =  70000\n",
      "data size =  70100\n",
      "data size =  70200\n",
      "data size =  70300\n",
      "data size =  70400\n",
      "data size =  70500\n",
      "data size =  70600\n",
      "data size =  70700\n",
      "data size =  70800\n",
      "data size =  70900\n",
      "data size =  71000\n",
      "data size =  71100\n",
      "data size =  71200\n",
      "data size =  71300\n",
      "data size =  71400\n",
      "data size =  71500\n",
      "data size =  71600\n",
      "data size =  71700\n",
      "data size =  71800\n",
      "data size =  71900\n",
      "data size =  72000\n",
      "data size =  72100\n",
      "data size =  72200\n",
      "data size =  72300\n",
      "data size =  72400\n",
      "data size =  72500\n",
      "data size =  72600\n",
      "data size =  72700\n",
      "data size =  72800\n",
      "data size =  72900\n",
      "data size =  73000\n",
      "data size =  73100\n",
      "data size =  73200\n",
      "data size =  73300\n",
      "data size =  73400\n",
      "data size =  73500\n",
      "data size =  73600\n",
      "data size =  73700\n",
      "data size =  73800\n",
      "data size =  73900\n",
      "data size =  74000\n",
      "data size =  74100\n",
      "data size =  74200\n",
      "data size =  74300\n",
      "data size =  74400\n",
      "data size =  74500\n",
      "data size =  74600\n",
      "data size =  74700\n",
      "data size =  74800\n",
      "data size =  74900\n",
      "data size =  75000\n",
      "data size =  75100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size =  75200\n",
      "data size =  75300\n",
      "data size =  75400\n",
      "data size =  75500\n",
      "data size =  75600\n",
      "data size =  75700\n",
      "data size =  75800\n",
      "data size =  75900\n",
      "data size =  76000\n",
      "data size =  76100\n",
      "data size =  76200\n",
      "data size =  76300\n",
      "data size =  76400\n",
      "data size =  76500\n",
      "data size =  76600\n",
      "data size =  76700\n",
      "data size =  76800\n",
      "data size =  76900\n",
      "data size =  77000\n",
      "data size =  77100\n",
      "data size =  77200\n",
      "data size =  77300\n",
      "data size =  77400\n",
      "data size =  77500\n",
      "data size =  77600\n",
      "data size =  77700\n",
      "data size =  77800\n",
      "data size =  77900\n",
      "data size =  78000\n",
      "data size =  78100\n",
      "data size =  78200\n",
      "data size =  78300\n",
      "data size =  78400\n",
      "data size =  78500\n",
      "data size =  78600\n",
      "data size =  78700\n",
      "data size =  78800\n",
      "data size =  78900\n",
      "data size =  79000\n",
      "data size =  79100\n",
      "data size =  79200\n",
      "data size =  79300\n",
      "data size =  79400\n",
      "data size =  79500\n",
      "data size =  79600\n",
      "data size =  79700\n",
      "data size =  79800\n",
      "data size =  79900\n",
      "data size =  80000\n",
      "data size =  80100\n",
      "data size =  80200\n",
      "data size =  80300\n",
      "data size =  80400\n",
      "data size =  80500\n",
      "data size =  80600\n",
      "data size =  80700\n",
      "data size =  80800\n",
      "data size =  80900\n",
      "data size =  81000\n",
      "data size =  81100\n",
      "data size =  81200\n",
      "data size =  81300\n",
      "data size =  81400\n",
      "data size =  81500\n",
      "data size =  81600\n",
      "data size =  81700\n",
      "data size =  81800\n",
      "data size =  81900\n",
      "data size =  82000\n",
      "data size =  82100\n",
      "data size =  82200\n",
      "data size =  82300\n",
      "data size =  82400\n",
      "data size =  82500\n",
      "data size =  82600\n",
      "data size =  82700\n",
      "data size =  82800\n",
      "data size =  82900\n",
      "data size =  83000\n",
      "data size =  83100\n",
      "data size =  83200\n",
      "data size =  83300\n",
      "data size =  83400\n",
      "data size =  83500\n",
      "data size =  83600\n",
      "data size =  83700\n",
      "data size =  83800\n",
      "data size =  83900\n",
      "data size =  84000\n",
      "data size =  84100\n",
      "data size =  84200\n",
      "data size =  84300\n",
      "data size =  84400\n",
      "data size =  84500\n",
      "data size =  84600\n",
      "data size =  84700\n",
      "data size =  84800\n",
      "data size =  84900\n",
      "data size =  85000\n",
      "data size =  85100\n",
      "data size =  85200\n",
      "data size =  85300\n",
      "data size =  85400\n",
      "data size =  85500\n",
      "data size =  85600\n",
      "data size =  85700\n",
      "data size =  85800\n",
      "data size =  85900\n",
      "data size =  86000\n",
      "data size =  86100\n",
      "data size =  86200\n",
      "data size =  86300\n",
      "data size =  86400\n",
      "data size =  86500\n",
      "data size =  86600\n",
      "data size =  86700\n",
      "data size =  86800\n",
      "data size =  86900\n",
      "data size =  87000\n",
      "data size =  87100\n",
      "data size =  87200\n",
      "data size =  87300\n",
      "data size =  87400\n",
      "data size =  87500\n",
      "data size =  87600\n",
      "data size =  87700\n",
      "data size =  87800\n",
      "data size =  87900\n",
      "data size =  88000\n",
      "data size =  88100\n",
      "data size =  88200\n",
      "data size =  88300\n",
      "data size =  88400\n",
      "data size =  88500\n",
      "data size =  88600\n",
      "data size =  88700\n",
      "data size =  88800\n",
      "data size =  88900\n",
      "data size =  89000\n",
      "data size =  89100\n",
      "data size =  89200\n",
      "data size =  89300\n",
      "data size =  89400\n",
      "data size =  89500\n",
      "data size =  89600\n",
      "data size =  89700\n",
      "data size =  89800\n",
      "data size =  89900\n",
      "data size =  90000\n",
      "data size =  90100\n",
      "data size =  90200\n",
      "data size =  90300\n",
      "data size =  90400\n",
      "data size =  90500\n",
      "data size =  90600\n",
      "data size =  90700\n",
      "data size =  90800\n",
      "data size =  90900\n",
      "data size =  91000\n",
      "data size =  91100\n",
      "data size =  91200\n",
      "data size =  91300\n",
      "data size =  91400\n",
      "data size =  91500\n",
      "data size =  91600\n",
      "data size =  91700\n",
      "data size =  91800\n",
      "data size =  91900\n",
      "data size =  92000\n",
      "data size =  92100\n",
      "data size =  92200\n",
      "data size =  92300\n",
      "data size =  92400\n",
      "data size =  92500\n",
      "data size =  92600\n",
      "data size =  92700\n",
      "data size =  92800\n",
      "data size =  92900\n",
      "data size =  93000\n",
      "data size =  93100\n",
      "data size =  93200\n",
      "data size =  93300\n",
      "data size =  93400\n",
      "data size =  93500\n",
      "data size =  93600\n",
      "data size =  93700\n",
      "data size =  93800\n",
      "data size =  93900\n",
      "data size =  94000\n",
      "data size =  94100\n",
      "data size =  94200\n",
      "data size =  94300\n",
      "data size =  94400\n",
      "data size =  94500\n",
      "data size =  94600\n",
      "data size =  94700\n",
      "data size =  94800\n",
      "data size =  94900\n",
      "data size =  95000\n",
      "data size =  95100\n",
      "data size =  95200\n",
      "data size =  95300\n"
     ]
    }
   ],
   "source": [
    "thrds = []\n",
    "for i in range(0,(file_size//batch_size)+1):\n",
    "    #translate(str(i))\n",
    "    try:\n",
    "        '''\n",
    "        if(False):\n",
    "           #_thread.start_new_thread(translate, (str(i)))\n",
    "           print(str(i))\n",
    "           my = M()\n",
    "           td =  threading.Thread(target=M.t, args = (str(i),))\n",
    "           td.start()\n",
    "           thrds.append(td)\n",
    "        else:\n",
    "        '''\n",
    "        print(\"processing file = \", str(i))\n",
    "        td =  threading.Thread(target=translate, args = (i,))\n",
    "        td.start()\n",
    "        thrds.append(td)\n",
    "       \n",
    "    except:\n",
    "        print(\"Error: unable to start thread\")\n",
    "\n",
    "for td in thrds:\n",
    "    td.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unique_data_processed_with_Date_multithread_idx_400_feb_06_v2.json', 'w', encoding=\"utf8\") as f:  # writing JSON object\n",
    "    json.dump(unique_data_processed, f)\n",
    "#12:20pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95352"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_data_processed)\n",
    "#unique_data_processed[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data_processed[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Thread Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data_processed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    process(unique_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Change Trigger Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "def read(path):\n",
    "    return open(path, 'r', encoding = 'utf-8').read()\n",
    "\n",
    "\n",
    "BASE=\"C:/research_stuff/codes\"\n",
    "unique_data = getJsonData('E:/APR/DATA/unique_data_processed_with_Date_multithread_idx_400_feb_03.json')\n",
    "print(unique_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getJsonData('unique_data_processed_with_Date_multithread.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data[0]['source'])\n",
    "print(\"===================\")\n",
    "print(data[0]['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_file_name = unique_data[i]['file_name']\n",
    "base_patch_number = unique_data[i]['base_patch_number']\n",
    "changed_patch_number = unique_data[i]['changed_patch_number']\n",
    "main_code_path = BASE+code_file_name+'/'+str(base_patch_number)+'.java'\n",
    "changed_code_path = BASE+code_file_name+'/'+str(changed_patch_number)+'.java'\n",
    "line_no = unique_data[i]['line_number']\n",
    "main_code = read(main_code_path)\n",
    "changed_code = read(changed_code_path)\n",
    "sample = main_code\n",
    "message = unique_data[i]['message']\n",
    "comment_id = unique_data[i]['comment_id']\n",
    "source = \"\"\n",
    "target=''\n",
    "source, target = get_source_target(main_code_path, changed_code_path,line_no-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(message)\n",
    "print(\"######################\")\n",
    "print(target)\n",
    "print(\"######################\")\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(unique_data_processed[i]['message'])\n",
    "print(\"##################################\")\n",
    "print(unique_data_processed[i]['target'])\n",
    "print(\"##################################\")\n",
    "print(unique_data_processed[i]['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "code = unique_data_processed[30]\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_code_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data_processed[0]['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data_processed[0]['target'][:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "i = random.randint(0,len(unique_data))\n",
    "\n",
    "unique_data_processed = []\n",
    "process(unique_data[i])\n",
    "\n",
    "print(\"Data Number: \", i)\n",
    "print(\"##################################\")\n",
    "print(unique_data_processed[0]['status'])\n",
    "print(\"##################################\")\n",
    "print(unique_data_processed[0]['message'])\n",
    "print(\"##################################\")\n",
    "print(unique_data_processed[0]['target'])\n",
    "print(\"##################################\")\n",
    "print(unique_data_processed[0]['code_snippet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_data_processed[0]['func_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data_processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data2 = unique_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for i in range(len(unique_data2)):\n",
    "    unique_data2[i]['global_index'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data2[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unique_data_with_date_and_index.json', 'w', encoding=\"utf8\") as f:  # writing JSON object\n",
    "    json.dump(unique_data2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Data, Removing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tufano_test_50 = [13257, 10443, 21152, 8344, 6123, 6122, 21086, 9006, 14137, 2523, 20560, 19915, 11901, 21693, 11107, 2862, 17879, 12346, 14420, 3304, 20658, 13924, 21678, 1945, 19047, 4809, 16525, 21206, 14443, 21481, 5892, 13829, 13432, 5099, 4386, 11997, 19914, 12053, 2593, 10330, 15305, 11388, 3721, 20969, 5081, 1698, 10571, 18025, 15679, 17847, 11928, 11603, 4889, 2275, 2486, 19685, 5751, 8624, 7797, 17666, 7386, 3637, 5322, 15897, 19141, 18152, 9304, 10875, 11265, 10798, 4037, 20348, 1523, 11467, 8681, 3425, 9065, 3218, 10253, 13353, 2653, 14120, 16091, 2254, 7186, 6130, 8591, 9508, 5079, 2852, 13805, 11996, 20144, 13898, 8802, 14704, 18353, 5013, 10893, 21737, 2146, 14135, 8558, 12660, 11119, 14087, 3666, 10010, 21986, 11362, 13777, 14591, 9078, 16886, 11084, 8497, 21973, 3012, 6120, 10343, 11429, 12975, 16540, 6691, 15168, 17916, 12147, 4926, 11437, 13825, 19745, 21110, 2824, 11167, 3949, 10816, 10579, 15102, 13452, 9525, 3361, 5752, 11120, 8512, 17598, 13134, 3389, 17098, 12098, 20887, 12875, 11401, 10811, 19452, 11042, 20528, 18278, 8801, 7395, 7634, 13026, 14750, 12598, 2134, 15328, 19022, 17539, 18903, 20678, 17284, 2698, 19401, 8613, 21682, 13847, 15378, 8760, 19787, 12348, 6266, 5039, 9425, 12811, 16796, 12824, 4066, 8307, 2391, 4808, 17597, 20049, 14315, 13013, 15698, 2851, 2778, 17500, 13803, 6042, 20000, 3333, 18905, 2113, 17724, 8840, 20665, 21543, 10030, 14929, 10877, 14961, 3141, 17846, 13344, 10153, 5940, 12649, 14890, 14759, 21421, 10709, 3897, 3007, 20834, 21107, 7277, 11720, 11016, 3132, 10841, 17746, 20477, 4076, 16242, 21175, 10139, 16452, 10316, 15003, 9490, 20271, 20888, 7093, 19349, 9007, 6101, 11181, 14823, 12253, 1996, 18145, 14751, 9972, 9596, 12088, 19747, 11083, 9567, 12603, 11750, 5546, 4447, 4172, 10231, 1650, 2514, 6627, 18772, 16202, 5078, 13562, 19487, 14082, 11099, 20145, 8017, 2859, 20371, 5300, 4534, 10822, 10089, 7806, 17574, 17865, 7658, 20993, 12764, 18782, 19060, 7917, 17068, 19092, 16548, 14880, 19254, 2046, 5105, 20178, 6343, 12439, 18995, 21093, 7637, 18155, 11978, 17798, 12613, 20820, 21919, 8003, 21297, 6125, 14429, 20179, 15169, 6131, 12874, 18760, 1402, 5474, 20450, 2408, 10968, 4168, 13885, 11620, 10380, 1518, 14043, 2093, 12839, 17671, 1764, 4088, 18904, 2433, 17884, 9189, 8978, 8953, 18781, 1467, 14927, 13354, 16361, 11101, 10873, 18126, 15104, 16655, 9019, 20718, 12065, 14791, 20213, 15955, 17754, 18763, 21618, 21132, 7185, 5684, 4455, 14855, 5415, 7214, 14058, 4021, 18969, 4820, 15936, 8065, 3724, 11624, 16604, 20508, 7767, 15567, 14923, 16698, 6243, 9487, 12865, 2864, 11176, 13093, 2860, 5379, 2879, 12283, 19458, 17392, 7718, 4585, 21436, 17247, 5705, 4735, 2386]\n",
    "tufano_test_100 = [5465, 15764, 18264, 11017, 17135, 7848, 21592, 15676, 4869, 20105, 15796, 12010, 6956, 13149, 3673, 5991, 21519, 13763, 7374, 16092, 5043, 12551, 14357, 17860, 17187, 13954, 7030, 6202, 3467, 13696, 10996, 10205, 16827, 17144, 7037, 13859, 8467, 14869, 10480, 4893, 8712, 19648, 11063, 10037, 10857, 3957, 14268, 11575, 8316, 3794, 10844, 20940, 11465, 15763, 13030, 6917, 12043, 21798, 17757, 18194, 19258, 4191, 16231, 18081, 9406, 18148, 18118, 15061, 2886, 21260, 11596, 15238, 6756, 12052, 18150, 4086, 7969, 3802, 15128, 4891, 6204, 6094, 21280, 13208, 3800, 12828, 15638, 6190, 5044, 7581, 11108, 7463, 21699, 12292, 12012, 20156, 21525, 16585, 13428, 11331, 11973, 18106, 21605, 4316, 4193, 9350, 8132, 16085, 4081, 17251, 10370, 5124, 12350, 16364, 9090, 8274, 12494, 5494, 4687, 19477, 8572, 16612, 9294, 8711, 4196, 18593, 2124, 7180, 1831, 4438, 19840, 18159, 15787, 16490, 10023, 20247, 18416, 5083, 4697, 18808, 14070, 13494, 8973, 10344, 13591, 19593, 19282, 21673, 12521, 3485, 15253, 5872, 19947, 3465, 10281, 1813, 7368, 13593, 8174, 7208, 6921, 15096, 21011, 9628, 13234, 14074, 14183, 15081, 18103, 8879, 10803, 15959, 13000, 8700, 19198, 5565, 7218, 16129, 11793, 20778, 21560, 5336, 7042, 11242, 18499, 12548, 13612, 5020, 10331, 7885, 2544, 8972, 14452, 3015, 3114, 1748, 9349, 14412, 2565, 4170, 3026, 20135, 21397, 6314, 17076, 20741, 17688, 6694, 16411, 17143, 20033, 10314, 16232, 20161, 3335, 2277, 9411, 2123, 16420, 18312, 4154, 20672, 5019, 8628, 17760, 12749, 20394, 19806, 3058, 12474, 18299, 1820, 15313, 4827, 3370, 15144, 18121, 8573, 4085, 11187, 19948, 17911, 2590, 14870, 11705, 6870, 11654, 16197, 10479, 14051, 12321, 1552, 7239, 2104, 18160, 14986, 10442, 16412, 9450, 10686, 9053, 4821, 6395, 1545, 5694, 8936, 12944, 3977, 7842, 1757, 2644, 6869, 6765, 14451, 9992, 17012, 18331, 6779, 13637, 12173, 10576, 14858, 10516, 7426, 5115, 15713, 2681, 6075, 15603, 21981, 7259, 8503, 7850, 5965, 15727, 8719, 10587, 3630, 20031, 13826, 18817, 9471, 11749, 5048, 11974, 3985, 6758, 9347, 3881, 13521, 5181, 20011, 13934, 13809, 15623, 6211, 17495, 6778, 6191, 15502, 16858, 11014, 7260, 14354, 11856, 2586, 19851, 5356, 20594, 16856, 13276, 7308, 16449, 13305, 15417, 12493, 2888, 9054, 4437, 4892, 19975, 12880, 3911, 14444, 9263, 12051, 7571, 11824, 12135, 21252, 16170, 21654, 15948, 13267, 5495, 6926, 3412, 19478, 5164, 12659, 16047, 2106, 9728, 21580, 12217, 19857, 7608, 15222, 15249, 7613, 19476, 11062, 12684, 2887, 3431, 13733, 12947, 4023, 6955, 11226, 11259, 5726, 11879, 16857, 8814, 16203, 17026, 15139, 12464, 13476, 1926, 14057, 14316, 12627, 4080, 5126, 10382, 1873, 12296, 20347]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import traceback\n",
    "\n",
    "def merge_code_comment(x):\n",
    "    message = x['message']\n",
    "    source = ' '.join(x['tokenized_code_snippet'])\n",
    "    target = ' '.join(x['target'])\n",
    "    merged = message + '<>' + source + '<>' + target\n",
    "    return merged\n",
    "\n",
    "existing_ids = set()\n",
    "duplicate_ids = set()\n",
    "unique_dat = []\n",
    "i = 0\n",
    "target_size = 400\n",
    "error_count = 0\n",
    "error_list = []\n",
    "\n",
    "for x in unique_data:\n",
    "    #print(dt['idx'])\n",
    "    #x = unique_data[dt['idx']]\n",
    "    i+= 1\n",
    "    try:\n",
    "        focuslen = x['tokenized_code_snippet'].index('<|endfocus|>') - x['tokenized_code_snippet'].index('<|startfocus|>')\n",
    "        key = merge_code_comment(x)\n",
    "        if key not in existing_ids and len(x['tokenized_target']) <= target_size and focuslen <= target_size:\n",
    "            existing_ids.add(key)\n",
    "            unique_dat.append(i-1)\n",
    "        elif key not in duplicate_ids:\n",
    "            duplicate_ids.add(key)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        x['error'] = e\n",
    "        error_list.append(x)\n",
    "        error_count += 1\n",
    "        #print(x)\n",
    "        #break\n",
    "print(len(unique_dat))\n",
    "\n",
    "\n",
    "global2loval = {}\n",
    "local2global = {}\n",
    "for i, d in enumerate(unique_data):\n",
    "    global2loval[d['global_index']] = i\n",
    "    local2global[i] = d['global_index']\n",
    "\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for i in unique_dat: #1:75\n",
    "    dt = unique_data[i]\n",
    "    #pprint(dt)\n",
    "    if dt['global_index'] not in tufano_test_50 and dt['global_index'] not in tufano_test_100:\n",
    "        '''data = {}\n",
    "        data['global_index'] = dt['global_index']\n",
    "        data['code_snippet'] =dt['code_snippet'] \n",
    "        data['tokenized_code_snippet']=dt['tokenized_code_snippet']\n",
    "        data['message']=dt['message']\n",
    "        data['tokenized_comment']=dt['tokenized_comment']\n",
    "        data['target']=dt['target']\n",
    "        data['tokenized_target']=dt['tokenized_target']'''\n",
    "        training_data.append(dt)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_data.json', 'w', encoding=\"utf8\") as f:  # writing JSON object\n",
    "    json.dump(training_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getJsonData('unique_data_processed_with_multithread_v2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['status', 'message', 'comment_id', 'target', 'code_snippet', 'prime_var_dic', 'class_list', 'func_list', 'tokenized_code_snippet', 'tokenized_target', 'tokenized_comment', 'global_index', 'base_code_line_number', 'base_patch_number', 'changed_patch_number', 'code_file_name', 'line_change', 'written_on', 'project_name'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68291\n"
     ]
    }
   ],
   "source": [
    "changed_training_data = []\n",
    "statuses = ['none', 'unchanged']\n",
    "for x in data:\n",
    "    if x['status'] in statuses:\n",
    "        continue\n",
    "    changed_training_data.append(x)\n",
    "print(len(changed_training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'update',\n",
       " 'message': 'Not using standard indentation style.',\n",
       " 'comment_id': 'AAAA8H%2F%2F9%2Bw%3D',\n",
       " 'target': '                CalendarPreferenceActivity.SHARED_PREFS_NAME));\\n',\n",
       " 'code_snippet': '    public void onCreate () {\\n        addHelper(SHARED_KEY, new SharedPreferencesBackupHelper(this,\\n<|startfocus|>\\n                                                                CalendarPreferenceActivity.SHARED_PREFS_NAME));\\n<|endfocus|>',\n",
       " 'prime_var_dic': {'SHARED_KEY': 1},\n",
       " 'class_list': ['CalendarBackupAgent'],\n",
       " 'func_list': ['public void onCreate ()'],\n",
       " 'tokenized_code_snippet': ['<|4-s|>',\n",
       "  'public',\n",
       "  '<|s|>',\n",
       "  'void',\n",
       "  '<|s|>',\n",
       "  'on',\n",
       "  'Create',\n",
       "  '<|s|>',\n",
       "  '(',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '{',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  'add',\n",
       "  'Helper',\n",
       "  '(',\n",
       "  'SHARED',\n",
       "  '_',\n",
       "  'KEY',\n",
       "  ',',\n",
       "  '<|s|>',\n",
       "  'new',\n",
       "  '<|s|>',\n",
       "  'Shared',\n",
       "  'Preferences',\n",
       "  'Backup',\n",
       "  'Helper',\n",
       "  '(',\n",
       "  'this',\n",
       "  ',',\n",
       "  '<|nl|>',\n",
       "  '<|startfocus|>',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  '<|16-s|>',\n",
       "  '<|16-s|>',\n",
       "  '<|16-s|>',\n",
       "  'Calendar',\n",
       "  'Preference',\n",
       "  'Activity',\n",
       "  '.',\n",
       "  'SHARED',\n",
       "  '_',\n",
       "  'PREFS',\n",
       "  '_',\n",
       "  'NAME',\n",
       "  ')',\n",
       "  ');',\n",
       "  '<|nl|>',\n",
       "  '<|endfocus|>'],\n",
       " 'tokenized_target': ['<|16-s|>',\n",
       "  'Calendar',\n",
       "  'Preference',\n",
       "  'Activity',\n",
       "  '.',\n",
       "  'SHARED',\n",
       "  '_',\n",
       "  'PREFS',\n",
       "  '_',\n",
       "  'NAME',\n",
       "  ')',\n",
       "  ');',\n",
       "  '<|nl|>'],\n",
       " 'tokenized_comment': ['Not',\n",
       "  '<|s|>',\n",
       "  'using',\n",
       "  '<|s|>',\n",
       "  'standard',\n",
       "  '<|s|>',\n",
       "  'indentation',\n",
       "  '<|s|>',\n",
       "  'style',\n",
       "  '.'],\n",
       " 'global_index': 19000,\n",
       " 'base_code_line_number': 12,\n",
       " 'base_patch_number': 1,\n",
       " 'changed_patch_number': 2,\n",
       " 'code_file_name': 'android_4283',\n",
       " 'line_change': 0,\n",
       " 'written_on': '2010-10-29 01:47:44',\n",
       " 'project_name': 'android_'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['android_', 'acumos_', 'asterix_', 'cloudera_', 'couchbase_', 'eclipse_', 'fd_', 'gerrithub_', 'googlereview_', 'iotivity_', 'carbonrom_', 'omnirom_', 'dirtyunicorn_', 'opencord_', 'polarsys_']\n"
     ]
    }
   ],
   "source": [
    "unique_project_names = []\n",
    "for x in unique_data:\n",
    "    if x['project_name'] not in unique_project_names:\n",
    "        unique_project_names.append(x['project_name'])\n",
    "print(unique_project_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Date wise calculation\n",
    "oct19 = datetime.strptime('2018-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def to_integer(str_date_time):\n",
    "    dt_time = datetime.strptime(str_date_time, '%Y-%m-%d %H:%M:%S')\n",
    "    return 10000*dt_time.year + 100*dt_time.month + dt_time.day\n",
    "\n",
    "#    date_string = x['written_on']\n",
    "#    date = datetime.strptime(date_string, '%Y-%m-%d %H:%M:%S')\n",
    "#    if date > oct19:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(changed_training_data)):\n",
    "    str_date = changed_training_data[i]['written_on']\n",
    "    changed_training_data[i]['int_date'] = to_integer(str_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20101029"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_training_data[0]['int_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_wise_test = {}\n",
    "for x in unique_project_names:\n",
    "    project_wise_test[x] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in changed_training_data:\n",
    "    project = x['project_name']\n",
    "    project_wise_test[project].append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('all_data_with_date_integer.json', 'w', encoding=\"utf8\") as f:  # writing JSON object\n",
    "    json.dump(changed_training_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 5% as testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android_ 15693\n",
      "acumos_ 1097\n",
      "asterix_ 10296\n",
      "cloudera_ 4724\n",
      "couchbase_ 1031\n",
      "eclipse_ 14235\n",
      "fd_ 754\n",
      "gerrithub_ 1613\n",
      "googlereview_ 17101\n",
      "iotivity_ 1031\n",
      "carbonrom_ 26\n",
      "omnirom_ 292\n",
      "dirtyunicorn_ 22\n",
      "opencord_ 71\n",
      "polarsys_ 305\n",
      "64884 3407\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "train_by_project = []\n",
    "test_by_project = []\n",
    "for x in project_wise_test:\n",
    "    print(x, len(project_wise_test[x]))\n",
    "    #shuffle(project_wise_test[x])\n",
    "    project_wise_test[x] = sorted(project_wise_test[x], key=lambda k: k['int_date'])\n",
    "    num_test = len(project_wise_test[x])//20\n",
    "    #for p in project_wise_test[x][:100]:\n",
    "    #    print(p['int_date'])\n",
    "    train_by_project = train_by_project + project_wise_test[x][:len(project_wise_test[x])-num_test]\n",
    "    test_by_project = test_by_project + project_wise_test[x][-num_test:]\n",
    "    '''\n",
    "    for i in range(len(project_wise_test[x])):\n",
    "        if i<num_test:\n",
    "            test_by_project.append(project_wise_test[x][i])\n",
    "        else:\n",
    "            train_by_project.append(project_wise_test[x][i])\n",
    "    '''\n",
    "print(len(train_by_project), len(test_by_project))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('train_by_project.json', 'w', encoding=\"utf8\") as f:  # writing JSON object\n",
    "    json.dump(train_by_project, f)\n",
    "\n",
    "import json\n",
    "with open('test_by_project.json', 'w', encoding=\"utf8\") as f:  # writing JSON object\n",
    "    json.dump(test_by_project, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'update',\n",
       " 'message': 'If system type is an int, why not store it as an int instead of as a String, and avoid calling parseInt()?',\n",
       " 'comment_id': 'z63b29270a22c525cdca47cbbc7e98d7b',\n",
       " 'target': '        if(ss.getRadioTechnology() == ServiceState.RADIO_TECHNOLOGY_1xRTT \\n                || ss.getRadioTechnology() == ServiceState.RADIO_TECHNOLOGY_EVDO_0\\n                || ss.getRadioTechnology() == ServiceState.RADIO_TECHNOLOGY_EVDO_A \\n                || ss.getRadioTechnology() == ServiceState.RADIO_TECHNOLOGY_IS95A\\n                || ss.getRadioTechnology() == ServiceState.RADIO_TECHNOLOGY_IS95B) {\\n            switch(ss.getExtendedCdmaRoaming()) {\\n',\n",
       " 'code_snippet': '        else if (asu >= 8)  asu = 3;\\n        else if (asu >= 4)  asu = 2;\\n        else asu = 1;\\n\\n        int[] iconList;\\n        if (mPhone.isNetworkRoaming()) {\\n            iconList = sSignalImages_r;\\n        } else {\\n            iconList = sSignalImages;\\n        }\\n        \\n<|startfocus|>\\n        //TODO Fill in static final ints instead of magic numbers\\n        try {\\n            if(Integer.parseInt(ss.getSystemType()) == 2 || Integer.parseInt(ss.getSystemType()) == 3) {\\n                switch(ss.getExtendedCdmaRoaming()) {\\n<|endfocus|>\\n                case ServiceState.REGISTRATION_STATE_ROAMING:\\n                    iconList = this.sSignalImages_r_cdma;\\n                    break;\\n                case ServiceState.REGISTRATION_STATE_ROAMING_AFFILIATE:\\n                    iconList = this.sSignalImages_ra_cdma;\\n                    break;\\n                default:\\n                    iconList = this.sSignalImages_cdma;\\n                break;   \\n                }\\n            }\\n        }\\n        catch(NumberFormatException ex) {\\n            Log.w(TAG, \"Warining! The systemType variable, needed for cdma, is not yet set.\");\\n        }\\n\\n\\n        mPhoneData.iconId = iconList[asu];',\n",
       " 'prime_var_dic': {'into': 1, 'int': 1},\n",
       " 'class_list': ['contains', 'StatusBarPolicy', 'StatusBarHandler'],\n",
       " 'func_list': ['public void onReceive(Context context, Intent intent)',\n",
       "  'private StatusBarPolicy(Context context, StatusBarService service)',\n",
       "  'public static void installIcons(Context context, StatusBarService service)',\n",
       "  'private void pickNextBatteryLevel(int level)',\n",
       "  'private void showBatteryView()',\n",
       "  'private void setBatteryLevel(View parent, int id, int height, int background, int level)',\n",
       "  'private void showLowBatteryWarning()',\n",
       "  'public void onDismiss(DialogInterface dialog)',\n",
       "  'private void scheduleCloseBatteryView()',\n",
       "  'private void closeLastBatteryView()',\n",
       "  'public void onSignalStrengthChanged(int asu)',\n",
       "  'public void onServiceStateChanged(ServiceState state)',\n",
       "  'public void onCallStateChanged(int state, String incomingNumber)',\n",
       "  'public void onDataConnectionStateChanged(int state)',\n",
       "  'public void onDataActivity(int direction)',\n",
       "  'public void handleMessage(Message msg)',\n",
       "  'public void onReceive(Context context, Intent intent)',\n",
       "  'private StatusBarPolicy(Context context, StatusBarService service)',\n",
       "  'public static void installIcons(Context context, StatusBarService service)',\n",
       "  'private void pickNextBatteryLevel(int level)',\n",
       "  'private void showBatteryView()',\n",
       "  'private void setBatteryLevel(View parent, int id, int height, int background, int level)',\n",
       "  'private void showLowBatteryWarning()',\n",
       "  'public void onDismiss(DialogInterface dialog)',\n",
       "  'private void scheduleCloseBatteryView()',\n",
       "  'private void closeLastBatteryView()',\n",
       "  'public void onSignalStrengthChanged(int asu)',\n",
       "  'public void onServiceStateChanged(ServiceState state)',\n",
       "  'public void onCallStateChanged(int state, String incomingNumber)',\n",
       "  'public void onDataConnectionStateChanged(int state)',\n",
       "  'public void onDataActivity(int direction)',\n",
       "  'public void handleMessage(Message msg)'],\n",
       " 'tokenized_code_snippet': ['<|8-s|>',\n",
       "  'else',\n",
       "  '<|s|>',\n",
       "  'if',\n",
       "  '<|s|>',\n",
       "  '(',\n",
       "  'asu',\n",
       "  '<|s|>',\n",
       "  '>=',\n",
       "  '<|s|>',\n",
       "  '8',\n",
       "  ')',\n",
       "  '<|2-s|>',\n",
       "  'asu',\n",
       "  '<|s|>',\n",
       "  '=',\n",
       "  '<|s|>',\n",
       "  '3',\n",
       "  ';',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  'else',\n",
       "  '<|s|>',\n",
       "  'if',\n",
       "  '<|s|>',\n",
       "  '(',\n",
       "  'asu',\n",
       "  '<|s|>',\n",
       "  '>=',\n",
       "  '<|s|>',\n",
       "  '4',\n",
       "  ')',\n",
       "  '<|2-s|>',\n",
       "  'asu',\n",
       "  '<|s|>',\n",
       "  '=',\n",
       "  '<|s|>',\n",
       "  '2',\n",
       "  ';',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  'else',\n",
       "  '<|s|>',\n",
       "  'asu',\n",
       "  '<|s|>',\n",
       "  '=',\n",
       "  '<|s|>',\n",
       "  '1',\n",
       "  ';',\n",
       "  '<|nl|>',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  'int',\n",
       "  '[',\n",
       "  ']',\n",
       "  '<|s|>',\n",
       "  'icon',\n",
       "  'List',\n",
       "  ';',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  'if',\n",
       "  '<|s|>',\n",
       "  '(',\n",
       "  'm',\n",
       "  'Phone',\n",
       "  '.',\n",
       "  'is',\n",
       "  'Network',\n",
       "  'Roaming',\n",
       "  '(',\n",
       "  ')',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '{',\n",
       "  '<|nl|>',\n",
       "  '<|12-s|>',\n",
       "  'icon',\n",
       "  'List',\n",
       "  '<|s|>',\n",
       "  '=',\n",
       "  '<|s|>',\n",
       "  's',\n",
       "  'Signal',\n",
       "  'Images',\n",
       "  '_',\n",
       "  'r',\n",
       "  ';',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  '}',\n",
       "  '<|s|>',\n",
       "  'else',\n",
       "  '<|s|>',\n",
       "  '{',\n",
       "  '<|nl|>',\n",
       "  '<|12-s|>',\n",
       "  'icon',\n",
       "  'List',\n",
       "  '<|s|>',\n",
       "  '=',\n",
       "  '<|s|>',\n",
       "  's',\n",
       "  'Signal',\n",
       "  'Images',\n",
       "  ';',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  '}',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  '<|nl|>',\n",
       "  '<|startfocus|>',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  '//',\n",
       "  'TODO',\n",
       "  '<|s|>',\n",
       "  'Fill',\n",
       "  '<|s|>',\n",
       "  'in',\n",
       "  '<|s|>',\n",
       "  'static',\n",
       "  '<|s|>',\n",
       "  'final',\n",
       "  '<|s|>',\n",
       "  'ints',\n",
       "  '<|s|>',\n",
       "  'instead',\n",
       "  '<|s|>',\n",
       "  'of',\n",
       "  '<|s|>',\n",
       "  'magic',\n",
       "  '<|s|>',\n",
       "  'numbers',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  'try',\n",
       "  '<|s|>',\n",
       "  '{',\n",
       "  '<|nl|>',\n",
       "  '<|12-s|>',\n",
       "  'if',\n",
       "  '(',\n",
       "  'Integer',\n",
       "  '.',\n",
       "  'parse',\n",
       "  'Int',\n",
       "  '(',\n",
       "  'ss',\n",
       "  '.',\n",
       "  'get',\n",
       "  'System',\n",
       "  'Type',\n",
       "  '(',\n",
       "  ')',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '==',\n",
       "  '<|s|>',\n",
       "  '2',\n",
       "  '<|s|>',\n",
       "  '||',\n",
       "  '<|s|>',\n",
       "  'Integer',\n",
       "  '.',\n",
       "  'parse',\n",
       "  'Int',\n",
       "  '(',\n",
       "  'ss',\n",
       "  '.',\n",
       "  'get',\n",
       "  'System',\n",
       "  'Type',\n",
       "  '(',\n",
       "  ')',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '==',\n",
       "  '<|s|>',\n",
       "  '3',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '{',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  'switch',\n",
       "  '(',\n",
       "  'ss',\n",
       "  '.',\n",
       "  'get',\n",
       "  'Extended',\n",
       "  'Cdma',\n",
       "  'Roaming',\n",
       "  '(',\n",
       "  ')',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '{',\n",
       "  '<|nl|>',\n",
       "  '<|endfocus|>',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  'case',\n",
       "  '<|s|>',\n",
       "  'Service',\n",
       "  'State',\n",
       "  '.',\n",
       "  'REGISTRATION',\n",
       "  '_',\n",
       "  'STATE',\n",
       "  '_',\n",
       "  'ROAMING',\n",
       "  ':',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  '<|4-s|>',\n",
       "  'icon',\n",
       "  'List',\n",
       "  '<|s|>',\n",
       "  '=',\n",
       "  '<|s|>',\n",
       "  'this',\n",
       "  '.',\n",
       "  's',\n",
       "  'Signal',\n",
       "  'Images',\n",
       "  '_',\n",
       "  'r',\n",
       "  '_',\n",
       "  'cdma',\n",
       "  ';',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  '<|4-s|>',\n",
       "  'break',\n",
       "  ';',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  'case',\n",
       "  '<|s|>',\n",
       "  'Service',\n",
       "  'State',\n",
       "  '.',\n",
       "  'REGISTRATION',\n",
       "  '_',\n",
       "  'STATE',\n",
       "  '_',\n",
       "  'ROAMING',\n",
       "  '_',\n",
       "  'AFFILIATE',\n",
       "  ':',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  '<|4-s|>',\n",
       "  'icon',\n",
       "  'List',\n",
       "  '<|s|>',\n",
       "  '=',\n",
       "  '<|s|>',\n",
       "  'this',\n",
       "  '.',\n",
       "  's',\n",
       "  'Signal',\n",
       "  'Images',\n",
       "  '_',\n",
       "  'ra',\n",
       "  '_',\n",
       "  'cdma',\n",
       "  ';',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  '<|4-s|>',\n",
       "  'break',\n",
       "  ';',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  'default',\n",
       "  ':',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  '<|4-s|>',\n",
       "  'icon',\n",
       "  'List',\n",
       "  '<|s|>',\n",
       "  '=',\n",
       "  '<|s|>',\n",
       "  'this',\n",
       "  '.',\n",
       "  's',\n",
       "  'Signal',\n",
       "  'Images',\n",
       "  '_',\n",
       "  'cdma',\n",
       "  ';',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  'break',\n",
       "  ';',\n",
       "  '<|2-s|>',\n",
       "  '<|s|>',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  '}',\n",
       "  '<|nl|>',\n",
       "  '<|12-s|>',\n",
       "  '}',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  '}',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  'catch',\n",
       "  '(',\n",
       "  'Number',\n",
       "  'Format',\n",
       "  'Exception',\n",
       "  '<|s|>',\n",
       "  'ex',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '{',\n",
       "  '<|nl|>',\n",
       "  '<|12-s|>',\n",
       "  'Log',\n",
       "  '.',\n",
       "  'w',\n",
       "  '(',\n",
       "  'TAG',\n",
       "  ',',\n",
       "  '<|s|>',\n",
       "  '\"',\n",
       "  'Warining',\n",
       "  '!',\n",
       "  '<|s|>',\n",
       "  'The',\n",
       "  '<|s|>',\n",
       "  'system',\n",
       "  'Type',\n",
       "  '<|s|>',\n",
       "  'variable',\n",
       "  ',',\n",
       "  '<|s|>',\n",
       "  'needed',\n",
       "  '<|s|>',\n",
       "  'for',\n",
       "  '<|s|>',\n",
       "  'cdma',\n",
       "  ',',\n",
       "  '<|s|>',\n",
       "  'is',\n",
       "  '<|s|>',\n",
       "  'not',\n",
       "  '<|s|>',\n",
       "  'yet',\n",
       "  '<|s|>',\n",
       "  'set',\n",
       "  '.',\n",
       "  '\"',\n",
       "  ');',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  '}',\n",
       "  '<|nl|>',\n",
       "  '<|nl|>',\n",
       "  '<|nl|>',\n",
       "  '<|8-s|>',\n",
       "  'm',\n",
       "  'Phone',\n",
       "  'Data',\n",
       "  '.',\n",
       "  'icon',\n",
       "  'Id',\n",
       "  '<|s|>',\n",
       "  '=',\n",
       "  '<|s|>',\n",
       "  'icon',\n",
       "  'List',\n",
       "  '[',\n",
       "  'asu',\n",
       "  '];'],\n",
       " 'tokenized_target': ['<|8-s|>',\n",
       "  'if',\n",
       "  '(',\n",
       "  'ss',\n",
       "  '.',\n",
       "  'get',\n",
       "  'Radio',\n",
       "  'Technology',\n",
       "  '(',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '==',\n",
       "  '<|s|>',\n",
       "  'Service',\n",
       "  'State',\n",
       "  '.',\n",
       "  'RADIO',\n",
       "  '_',\n",
       "  'TECHNOLOGY',\n",
       "  '_',\n",
       "  '1',\n",
       "  'x',\n",
       "  'RTT',\n",
       "  '<|s|>',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  '||',\n",
       "  '<|s|>',\n",
       "  'ss',\n",
       "  '.',\n",
       "  'get',\n",
       "  'Radio',\n",
       "  'Technology',\n",
       "  '(',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '==',\n",
       "  '<|s|>',\n",
       "  'Service',\n",
       "  'State',\n",
       "  '.',\n",
       "  'RADIO',\n",
       "  '_',\n",
       "  'TECHNOLOGY',\n",
       "  '_',\n",
       "  'EVDO',\n",
       "  '_',\n",
       "  '0',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  '||',\n",
       "  '<|s|>',\n",
       "  'ss',\n",
       "  '.',\n",
       "  'get',\n",
       "  'Radio',\n",
       "  'Technology',\n",
       "  '(',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '==',\n",
       "  '<|s|>',\n",
       "  'Service',\n",
       "  'State',\n",
       "  '.',\n",
       "  'RADIO',\n",
       "  '_',\n",
       "  'TECHNOLOGY',\n",
       "  '_',\n",
       "  'EVDO',\n",
       "  '_',\n",
       "  'A',\n",
       "  '<|s|>',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  '||',\n",
       "  '<|s|>',\n",
       "  'ss',\n",
       "  '.',\n",
       "  'get',\n",
       "  'Radio',\n",
       "  'Technology',\n",
       "  '(',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '==',\n",
       "  '<|s|>',\n",
       "  'Service',\n",
       "  'State',\n",
       "  '.',\n",
       "  'RADIO',\n",
       "  '_',\n",
       "  'TECHNOLOGY',\n",
       "  '_',\n",
       "  'IS',\n",
       "  '95',\n",
       "  'A',\n",
       "  '<|nl|>',\n",
       "  '<|16-s|>',\n",
       "  '||',\n",
       "  '<|s|>',\n",
       "  'ss',\n",
       "  '.',\n",
       "  'get',\n",
       "  'Radio',\n",
       "  'Technology',\n",
       "  '(',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '==',\n",
       "  '<|s|>',\n",
       "  'Service',\n",
       "  'State',\n",
       "  '.',\n",
       "  'RADIO',\n",
       "  '_',\n",
       "  'TECHNOLOGY',\n",
       "  '_',\n",
       "  'IS',\n",
       "  '95',\n",
       "  'B',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '{',\n",
       "  '<|nl|>',\n",
       "  '<|12-s|>',\n",
       "  'switch',\n",
       "  '(',\n",
       "  'ss',\n",
       "  '.',\n",
       "  'get',\n",
       "  'Extended',\n",
       "  'Cdma',\n",
       "  'Roaming',\n",
       "  '(',\n",
       "  ')',\n",
       "  ')',\n",
       "  '<|s|>',\n",
       "  '{',\n",
       "  '<|nl|>'],\n",
       " 'tokenized_comment': ['If',\n",
       "  '<|s|>',\n",
       "  'system',\n",
       "  '<|s|>',\n",
       "  'type',\n",
       "  '<|s|>',\n",
       "  'is',\n",
       "  '<|s|>',\n",
       "  'an',\n",
       "  '<|s|>',\n",
       "  'int',\n",
       "  ',',\n",
       "  '<|s|>',\n",
       "  'why',\n",
       "  '<|s|>',\n",
       "  'not',\n",
       "  '<|s|>',\n",
       "  'store',\n",
       "  '<|s|>',\n",
       "  'it',\n",
       "  '<|s|>',\n",
       "  'as',\n",
       "  '<|s|>',\n",
       "  'an',\n",
       "  '<|s|>',\n",
       "  'int',\n",
       "  '<|s|>',\n",
       "  'instead',\n",
       "  '<|s|>',\n",
       "  'of',\n",
       "  '<|s|>',\n",
       "  'as',\n",
       "  '<|s|>',\n",
       "  'a',\n",
       "  '<|s|>',\n",
       "  'String',\n",
       "  ',',\n",
       "  '<|s|>',\n",
       "  'and',\n",
       "  '<|s|>',\n",
       "  'avoid',\n",
       "  '<|s|>',\n",
       "  'calling',\n",
       "  '<|s|>',\n",
       "  'parse',\n",
       "  'Int',\n",
       "  '(',\n",
       "  ')',\n",
       "  '?'],\n",
       " 'global_index': 17933,\n",
       " 'base_code_line_number': 728,\n",
       " 'base_patch_number': 1,\n",
       " 'changed_patch_number': 2,\n",
       " 'code_file_name': 'android_4168',\n",
       " 'line_change': 0,\n",
       " 'written_on': '2008-12-03 16:11:17',\n",
       " 'project_name': 'android_',\n",
       " 'int_date': 20081203}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_by_project[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of total data: 85594\n",
    "Number of changed data: 68535\n",
    "none: 652\n",
    "unchanged: 16407\n",
    "insert: 5262\n",
    "delete: 11828\n",
    "update: 51445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "a = [2, 3]\n",
    "b = [5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_wise_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "def read(path):\n",
    "    return open(path, 'r', encoding = 'utf-8').read()\n",
    "\n",
    "\n",
    "BASE=\"C:/research_stuff/codes/\"\n",
    "unique = getJsonData('E:/APR/DATA/unique_data_with_date_and_index.json')\n",
    "unique_data = getJsonData('unique_data_processed_with_Date_multithread_idx_400_feb_06_v2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx , dt in enumerate(unique_data):\n",
    "    if(len(dt['tokenized_code_snippet']))>400:\n",
    "        #print(unique_data['global_index'])\n",
    "        #print(\"index = \", unique_data[idx]['global_index'])\n",
    "        #print(len(process(unique[unique_data[idx]['global_index']])['tokenized_code_snippet']))\n",
    "        if len(process(unique[unique_data[idx]['global_index']])['tokenized_code_snippet']) >400:\n",
    "            print(\"index = \", unique_data[idx]['global_index'], len(process(unique[unique_data[idx]['global_index']])['tokenized_code_snippet']))\n",
    "#process(unique_data[545])['code_snippet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95352\n",
      "11879\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(unique_data))\n",
    "ct=0\n",
    "for data in unique_data:\n",
    "    if data['code_snippet'][:14] == \"<|startfocus|>\" or data['code_snippet'][-13:] == \"\\n<|endfocus|>\":\n",
    "        ct+=1\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85440\n"
     ]
    }
   ],
   "source": [
    "def merge_code_comment(x):\n",
    "    message = x['message']\n",
    "    source = ' '.join(x['tokenized_code_snippet'])\n",
    "    target = ' '.join(x['target'])\n",
    "    merged = message + '<>' + source + '<>' + target\n",
    "    return merged\n",
    "\n",
    "existing_ids = set()\n",
    "duplicate_ids = set()\n",
    "unique_dat = []\n",
    "i = 0\n",
    "target_size = 400\n",
    "error_count = 0\n",
    "error_list = []\n",
    "\n",
    "for x in unique_data:\n",
    "    #print(dt['idx'])\n",
    "    #x = unique_data[dt['idx']]\n",
    "    i+= 1\n",
    "    try:\n",
    "        focuslen = x['tokenized_code_snippet'].index('<|endfocus|>') - x['tokenized_code_snippet'].index('<|startfocus|>')\n",
    "        key = merge_code_comment(x)\n",
    "        if key not in existing_ids and len(x['tokenized_target']) <= target_size and focuslen <= target_size:\n",
    "            existing_ids.add(key)\n",
    "            unique_dat.append(x)\n",
    "        elif key not in duplicate_ids:\n",
    "            duplicate_ids.add(key)\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        #x['error'] = e\n",
    "        error_list.append(x)\n",
    "        error_count += 1\n",
    "        #print(x)\n",
    "        #break\n",
    "print(len(unique_dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85440\n",
      "10632\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(unique_dat))\n",
    "ct=0\n",
    "for data in unique_dat:\n",
    "    if data['code_snippet'][:14] == \"<|startfocus|>\" or data['code_snippet'][-13:] == \"\\n<|endfocus|>\":\n",
    "        ct+=1\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\APR\\\\RepairFromReviewTrainingData'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
